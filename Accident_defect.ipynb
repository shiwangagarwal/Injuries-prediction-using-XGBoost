{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Highly_Fatal_And_Damaging' 'Significant_Damage_And_Fatalities'\n",
      " 'Significant_Damage_And_Serious_Injuries' ...\n",
      " 'Significant_Damage_And_Serious_Injuries'\n",
      " 'Significant_Damage_And_Serious_Injuries' 'Highly_Fatal_And_Damaging']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('testing/train.csv')\n",
    "test_df = pd.read_csv('testing/test.csv')\n",
    "\n",
    "# Combine training and test data to ensure consistent label encoding\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_df.drop(['Severity'], axis=1)\n",
    "y_train = train_df['Severity']\n",
    "X_test = test_df.copy()  # Make a copy of test data\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Define preprocessing steps using ColumnTransformer\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "categorical_cols_train = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, X_train.select_dtypes(include=['int64', 'float64']).columns),\n",
    "        ('cat', categorical_transformer, categorical_cols_train)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to training and test data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_processed, y_train_encoded)\n",
    "# Make predictions on the preprocessed test data\n",
    "test_predictions_encoded = model.predict(X_test_processed)\n",
    "\n",
    "# Inverse transform predicted labels back to original categories\n",
    "test_predictions = label_encoder.inverse_transform(test_predictions_encoded)\n",
    "\n",
    "# Create submission dataframe with Ids and predicted Severities\n",
    "submission_df = pd.DataFrame({\n",
    "    'Accident_ID': X_test['Accident_ID'],\n",
    "    'Severity': test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('testing/my_submission.csv', index=False)\n",
    "\n",
    "\n",
    "print(test_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
